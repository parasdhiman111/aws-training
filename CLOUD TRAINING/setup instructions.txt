--2nd Nov,2022

HI All..
Please take your assigned laptops to 1st Floor Training Room and verify following for tomorrow AWS training

1.
Cloud LAB: https://685421549691.signin.aws.amazon.com/console
username: test1
Password: Teamlease@321
TESTING Method : Try login to AWS Account with provided credentials and check if they are able to see EC2 servers in N. Virginia.

2.
Linux Server LAB: Server IP: 3.91.84.39
Username: root
Password: Tech@2020
TESTING Method : Use putty/other ssh client and try ssh to above server with provided credentials.
NOTE : Install putty from software directory (hr portal -> blue secure -> software repository -> download putty)

Do not share above credentials with anybody else.

Paras_Dhiman	8-T8LD3WAxbMGY-	https://685421549691.signin.aws.amazon.com/console

Access Key 
AKIAZ7FSO3B5ST5M4D3X
Secret Access Key
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

neha.shukla@teamlease.com
9819708434


[Paras Dhiman] 11/2/2022 11:03
https://els.teamleaseedtech.com/course/view.php?id=2454

[Paras Dhiman] 11/2/2022 11:09
https://els.teamleaseedtech.com/mod/quiz/view.php?id=54935


//Create a new user with no permissions

https://685421549691.signin.aws.amazon.com/console
Paras_Dhiman_test
cEG^bjLC(1TVV$R


//Adding administrator access to user

//Adding user to group 

//Adding specific permissions to user 

//Adding user to multiple groups 



--3rd Nov,2022

//Creating instance in EC2
EC2->LAUNCH INSTANCE
AMI-> Centos 7

Instance Type-> t2.micro

Key Pair Login -> public private key concept

Create new key pair
name
key pair type->RSA
Private key file format-> .pem


Network Settings

VPC
Subnet
Assign Public IP - for creating public instance if enabled


Firewall -AWS Secuirty Group

Storage - Root partition storge

//How to connect to Instance using ssh and other methods?

CLI :

sudo -i
yum update -y
yum install -y unzip
yum install -y wget
https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#cliv2-linux-install (copy the three commands)
ln -s  /usr/local/bin/aws  /usr/bin/
aws --version --To get the version of aws 






aws ec2 describe-instances | grep -i instanceid

Creation of an AWS Instance using CLI:
aws ec2 run-instances --image-id ami-033b95fb8079dc481 --instance-type t2.micro --key-name virginia-key
aws ec2 describe-instances | grep â€“i instanceid
aws ec2 stop-instances --instance-ids i-052af6a166198df10
aws ec2 terminate-instances --instance-ids i-052af6a166198df10





aws ec2 run-instances --image-id ami-0dee0f906cf114191 --instance-type t2.micro --key-name calif-paras 



//Load Balancers 

ALB :


two instance creation:
alb-ec2-C
alb-ec2-B

userdata :


#!/bin/bash
sudo yum update -y;
sudo yum install -y httpd;
sudo systemctl start httpd;
sudo systemctl enable httpd;
sudo echo "<h1>Hello World from $(hostname -f)</h1>" > /var/www/html/index.html

two security groups:

users--alb
alb---ec2


target group creation :
register both instances 



--4th Nov

Autoscaling

Create auto scaling template 
create launch template
add security group

add min,max,desired capacity



//default refresh health check time ==300 seconds

amazon-linux-extras install epel -y

yum install stress -y
stress--cpu 32


AUTOSCALING GROUP :


MANUAL SCALING



autoscaling :

stress commands :


sudo amazon-linux-extras install epel -y
sudo yum install stress -y
stress --cpu 16


centos - 
sudo yum install epel-release
sudo yum update -y
sudo yum install stress
stress --cpu 16



--7th Nov, 2022

Database as a Services -- RDS

AWS RDS High Availabilty with Multi Availability Zones

raman-vpc

public-subnet    : B

private-subnet : C



two instances :

public-instance     : B
prvte-instance      :C





peering :


172.31.0.0/16 default 



vpc -default  : instance-default

raman-vpc 


172.31.0.0/16 : defaults cidr


10.0.0.0/16 : raman-vpc cidr



# 1) encryption
aws kms encrypt --key-id alias/tutorial --plaintext fileb://ExampleSecretFile.txt --output text --query CiphertextBlob  --region eu-west-2 > ExampleSecretFileEncrypted.base64

# base64 decode for Linux or Mac OS
cat ExampleSecretFileEncrypted.base64 | base64 --decode > ExampleSecretFileEncrypted

# base64 decode for Windows
certutil -decode .\ExampleSecretFileEncrypted.base64 .\ExampleSecretFileEncrypted


# 2) decryption

aws kms decrypt --ciphertext-blob fileb://ExampleSecretFileEncrypted   --output text --query Plaintext > ExampleFileDecrypted.base64  --region eu-west-2

# base64 decode for Linux or Mac OS
cat ExampleFileDecrypted.base64 | base64 --decode > ExampleFileDecrypted.txt


# base64 decode for Windows
certutil -decode .\ExampleFileDecrypted.base64 .\ExampleFileDecrypted.txt 




--9th Nov,2022

Code commit credentials: 

username:
Paras_Dhiman-at-685421549691

password:
tYXm4nI3xWfX1KdSTDoTz/50NBfwM22G90HE9GkVSOk=




--10th Nov, 2022


ECS :



ECS CLUSTER : 1 CONTAINER INSTANCE/ECS HOST

1 TASK :
2WEBSERVERS : NGINX(81:80) HTTP(82:80)

VOLUME :


/bind-host :on host

/bind-nginx : inside container locations
/bind-httpd : as above


MANUALLY UPSCALING : 4 CONTAINER INSTANCES ..

1 SERVICE :
4 TASKS   : 2 CONGTAINERS EACH



EXPOSE UR WEBSERVERS AT http://18.144.51.76:82/ OR http://18.144.51.76:81



commands :


[ec2-user@ip-172-31-21-112 bind-host]$ history
    1  docker ps
    2  ls
    3  cd /
    4  ls
    5  cd bind-host
    6  ls
    7  mkdir ramankhanna
    8  ls
    9  sudo mkdir ramankhanna
   10  ls
   11  docker ps
   12  docker exec -it 1c2f09c11a05 /bin/bash
   13  docker ps
   14  docker exec -it f7c5bf95f86d /bin/bash
   15  history





------------------------------------------------------

   12  docker exec -it cc4deee3b4de/bin/bash




-----------------------
ECR :


raman:~/environment $ history
    1  docker ps
    2  docker pull httpd
    3  docker ps
    4  docker images
    5  aws ecr get-login-password --region us-west-1 | docker login --username AWS --password-stdin 685421549691.dkr.ecr.us-west-1.amazonaws.com
    6  docker tag raman-repo:latest 685421549691.dkr.ecr.us-west-1.amazonaws.com/raman-repo:latest
    7  docker tag httpd:latest 685421549691.dkr.ecr.us-west-1.amazonaws.com/raman-repo:latest
    8  docker images
    9  docker push 685421549691.dkr.ecr.us-west-1.amazonaws.com/raman-repo:latest
   10  clear
   11  docker images
   12  docker rmi -f 685421549691.dkr.ecr.us-west-1.amazonaws.com/raman-repo:latest
   13  docker images
   14  docker rmi -f httpd:latest
   15  docker images
   16  docker pull 685421549691.dkr.ecr.us-west-1.amazonaws.com/raman-repo:latest
   17  docker images
   18  docker run -dit 685421549691.dkr.ecr.us-west-1.amazonaws.com/raman-repo:latest
   19  dockder ps
   20  docker ps
   21  history
---------------------------------------









EKS cluster :

#on concsole , crete the raman-eks cluster and nodegroup

for eks cluster use iam policy in iam role : AmazonEKSClusterPolicy
for nodegroup creation : 
AmazonEKSWorkerNodePolicy
AmazonEC2ContainerRegistryReadOnly	
AmazonEKS_CNI_Policy

#download the aws cli wether on windows or linux ur tryingt o access the eks-cluster
for linux , create a amazonlinux env server on which aws cli is pre installed 

cli for windows:

https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

You must use a kubectl version that is within one minor version difference of your Amazon EKS cluster control plane. For example, a 1.21 kubectl client works with Kubernetes 1.20, 1.21 and 1.22 clusters.

download the binary acc to ur hardware of machine

#!/bin/bash
sudo echo -e "Tech@2020\nTech@2020" | passwd root;
sudo cp -p /etc/ssh/sshd_config /etc/ssh/sshd_config_backup;
sudo sed -i 's/^PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config;
sudo sed -i 's/^PermitRootLogin*/PermitRootLogin yes/' /etc/ssh/sshd_config;
sudo echo "PermitRootLogin yes" >> /etc/ssh/sshd_config;
sudo systemctl restart sshd;
sudo systemctl stop firewalld;
sudo systemctl disable firewalld;


aws configure  ,,,note : do not give an admin role to instance ; only do aws configure

#to connect it with raman-eks eks cluster , login to amzonlinuxenv server and install kubectl on it for linux
 https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html

chmod +x kubectl

#after installing kubectl ;

mv ./kubectl /usr/local/bin

#restart the session 

 kubectl get nodes
 aws eks update-kubeconfig --region us-east-2 --name raman-eks
 cat /root/.kube/config

# Install Docker on amazon linux

sudo yum update -y
sudo yum -y install docker

#Start Docker

sudo service docker start

#Access Docker commands in ec2-user user

sudo usermod -a -G docker ec2-user
sudo chmod 666 /var/run/docker.sock
docker version


 kubectl get nodes
 kubectl create deployment dep1 --image nginx --replicas=2
 kubectl get pods
 kubectl get pods -o wide

=========================

kubectl get pods
kubectl get svc
kubectl expose deployment dep1 --type LoadBalancer --port 80 --target-port 80
kubectl get svc

-------------

















commands :


 clear
    2  aws
    3  aws s3 ls
    4  aws configure
    5  aws s3 ls
    6  kubectl
    7  aws
    8  clear
    9  pwd
   10  curl -o kubectl https://s3.us-west-2.amazonaws.com/amazon-eks/1.22.6/2022-03-09/bin/linux/amd64/kubectl
   11  ls
   12  chmod +x kubectl
   13  ls
   14  mv ./kubectl /usr/local/bin
   15  sudo mv ./kubectl /usr/local/bin
   16  kubectl
   17  kubectl get nodes
   18   aws eks update-kubeconfig --region us-west-1 --name raman-eks
   19  clear
   20  kubectl get nodes
   21  kubectl get pods
   22  kubectl get pods -A
   23  kubectl create deployment dep1 --replicas 10 httpd
   24  kubectl create deployment dep1 --replicas 10 --image httpd
   25  kubectl get pods
   26  history




--11th Nov, 2022


provider "aws" {
 region = "us-east-2"
}

resource "aws_instance" "paras-ec2-tf" {
 ami = "ami-089a545a9ed9893b6"
 instance_type = "t2.micro"

 tags = {
  Name = "HelloWorld"
 }
}


tf :


https://registry.terraform.io/providers/hashicorp/aws/latest/docs


terraform command

sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform


ec2resource :

[root@ip-172-31-63-133 ~]# cat ec2.tf 
provider "aws" {
  region = "us-west-1"
}

resource "aws_instance" "myec2" {
  ami           = "ami-017c001a88dd93847"
  instance_type = "t3.micro"

  tags = {
    Name = "Raman-tf"
  }
}


commands:

terraform --version
    4  sudo yum install -y yum-utils
    5  sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
    6  sudo yum -y install terraform
    7  clear
    8  terraform --version
    9  pwd
   10  vi ec2.tf
   11  vi ec2.tf 
   12  cat ec2.tf 
   13  terraform validate
   14  ls -pa
   15  terraform init
   16  ls -a
   17  cd .terraform
   18  ls
   19  cd providers/
   20  ls
   21  cd registry.terraform.io/
   22  ls
   23  cd hashicorp/
   24  ls
   25  cd ..
   26  ls
   27  cd ..
   28  ls
   29  cd ..
   30  ls
   31  terraform plan
   32  ifconfig
   33  clear
   34  cat ec2.tf 
   35  terraform plan
   36  ls
   37  terraform apply
   38  ls
   39  cat ec2.tf 
   40  ls
   41  history
------------------------


gitv resource :

[root@ip-172-31-63-133 ~]# cat git.tf 
provider "github" {
  token = "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"
}

resource "github_repository" "git" {
  name        = "raman-repo"
  description = "My awesome codebase"

  visibility = "private"

  }




vi git.tf
   84  terraform validate
   85  terraform init
   86  ls -a
   87  cat .terraform.lock.hcl 
   88  clear
   89  terraform plan
   90  terraform apply
   91  clear
   92  terraform show
   93  terraform destroy
   94  terraform show
   95  terraform apply -auto-approve
   96  terraformshow
   97  terraform show
   98  clear
   99  cat ec2.tf 
  100  cat git.tf 
  101  terraform destroy -target github_repository.git
  102  terraform show
  103  history

----------------------------------



output_blocks :

output "myawsserver-publicIP" {
  value = [aws_instance.myec2.public_ip]
}

output "myawsserver-pvtIP" {
  value = [aws_instance.myec2.private_ip]


------------------------------------------------------

commands:

terraform --version
    4  sudo yum install -y yum-utils
    5  sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
    6  sudo yum -y install terraform
    7  clear
    8  terraform --version
    9  pwd
   10  vi ec2.tf
   11  vi ec2.tf 
   12  cat ec2.tf 
   13  terraform validate
   14  ls -pa
   15  terraform init
   16  ls -a
   17  cd .terraform
   18  ls
   19  cd providers/
   20  ls
   21  cd registry.terraform.io/
   22  ls
   23  cd hashicorp/
   24  ls
   25  cd ..
   26  ls
   27  cd ..
   28  ls
   29  cd ..
   30  ls
   31  terraform plan
   32  ifconfig
   33  clear
   34  cat ec2.tf 
   35  terraform plan
   36  ls
   37  terraform apply
   38  ls
   39  cat ec2.tf 
   40  ls
   41  history
------------------------


gitv resource :

[root@ip-172-31-63-133 ~]# cat git.tf 
provider "github" {
  token = "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"
}

resource "github_repository" "git" {
  name        = "raman-repo"
  description = "My awesome codebase"

  visibility = "private"

  }




vi git.tf
   84  terraform validate
   85  terraform init
   86  ls -a
   87  cat .terraform.lock.hcl 
   88  clear
   89  terraform plan
   90  terraform apply
   91  clear
   92  terraform show
   93  terraform destroy
   94  terraform show
   95  terraform apply -auto-approve
   96  terraformshow
   97  terraform show
   98  clear
   99  cat ec2.tf 
  100  cat git.tf 
  101  terraform destroy -target github_repository.git
  102  terraform show
  103  history

----------------------------------



remote-exec :


[root@ip-172-31-49-19 ~]# cat remote.tf 
provider "aws" {
region= "us-west-1"
}

resource "aws_instance" "myec2" {
   ami = "ami-017c001a88dd93847"                               #amazon linux ami
   instance_type = "t2.micro"
   key_name = "calif"                                 # Create a keypair in the region #
   vpc_security_group_ids  = [aws_security_group.allow_ssh.id]
   tags= {
   Name= "web-server"
   }

   provisioner "remote-exec" {
     inline = [
       "sudo amazon-linux-extras install -y nginx1.12",
       "sudo systemctl start nginx"
     ]

   connection {
     type = "ssh"
     user = "ec2-user"
     private_key = file("./calif.pem")    #copy the content of the private keyfile ; create a file in /root/app1 named nvirginia.pem and then paste the content into this file #
     host = self.public_ip
   }
   }
}

### NOTE - Adding a new security group resource to allow the terraform provisioner from laptop to connect to EC2 Instance via SSH.

resource "aws_security_group" "allow_ssh" {
  name        = "allow_ssh"
  description = "Allow SSH inbound traffic"
  vpc_id      = "vpc-0794f17e2346a1ab2"

  ingress {
    description = "SSH into VPC"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
 ingress {
    description = "SSH into VPC"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  egress {
    description = "Outbound Allowed"
    from_port   = 0
    to_port     = 65535
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}


-----------------------

-----------------------

local-exec :


[root@ip-172-31-49-19 ~]# cat local.tf 
provider "aws" {
region= "us-west-1"
}

resource "aws_instance" "myec2" {
   ami = "ami-017c001a88dd93847"
   instance_type = "t2.micro"

   provisioner "local-exec" {
    command = "echo ${aws_instance.myec2.private_ip} >> private_ips.txt"
}
}



-------------------------------


-------------------------------

[root@ip-172-31-49-19 ~]# cat myec2.tf 
provider "aws" {
  region = "us-west-1"
}

resource "aws_instance" "myawsserver" {
  ami = "ami-017c001a88dd93847"
  instance_type = var.type

  tags = {
    Name = "Techlanders-aws-ec2-instance"
  }
}





resource "aws_security_group" "var_demo" {
  name        = "raman-variables"
  vpc_id      = "vpc-0794f17e2346a1ab2"

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = [var.vpn_ip]
  }

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = [var.vpn_ip]
  }

  ingress {
    from_port   = 53
    to_port     = 53
    protocol    = "tcp"
    cidr_blocks = [var.vpn_ip]
  }
}


variable "type" {
default = "t2.micro"
}




--12th Nov, 2022


kubeadm join 172.31.33.75:6443 --token 75byug.pbtxm0stwdblnh5a --discovery-token-ca-cert-hash sha256:37bba29955d930fc1a0c499a9d58c5e72dd09ce112e7d8582d1afeec33a9a702



    1  hostnamectl set-hostname master
    2  vi script
    3  chmod +x script
    4  ./script
    5  kubectl get nodes
    6  kubectl get pods
    7  exit
    8  clear
    9  kubectl get pods
   10  kubectl get nodes
   11  kubectl get pods -A
   12  kubectl get pods -A -o wide
   13  kubectl run parasapp --image httpd
   14  kubectl get pods -A -o wide
   15  kubectl get pods
   16  kubectl get pods -A
   17  kubectl get pods
   18  history
   19  kubectl expose pod parasapp --type nodeport --name paras-nodeport-service --target-port 80 --port 80
   20  kubectl expose pod parasapp --type NodePort --name paras-nodeport-service --target-port 80 --port 80
   21  kubectl describe svc paras-nodeport-service
   22  kubectl describe svc
   23  history
   24  clear
   25  kubectl --help
   26  kubectl create --help
   27  kubectl create deployment deploy1 --image nginx --replicas 5
   28  kubectl get pods
   29  kubectl get rs
   30  kubectl get deploy
   31  kubectl expose deployment deploy1 --name extsvc2 --type NodePort --target-port 80 --port 80
   32  kubectl get svc
   33  kubectl describe extsvc2
   34  kubectl describe svc extsvc2
   35  kubectl get pods -o wide
   36  history
   37  kubectl get pods -o wide
   38  curl 172.31.33.75:30438
   39  kubectl get svc
   40  curl 172.31.33.75:31488
   41  kubectl scale deploy deploy1 --replicas 10
   42  kubectl get pods
   43  kubectl scale deploy deploy1 --replicas 2
   44  kubectl get pods
   45  history


---------------------------------------------------------------------------------------



ANSIBLE :


create three servers : amazon linux
ansible host , two nodes to push configurations on

1. Install Ansible using EPEL Repository
Download epel repository on the amazon linux 2 instance as follows,

$ wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
Next, Install epel repository using yum.

$ sudo yum install epel-release-latest-7.noarch.rpm
Update epel repository as follows,

$ sudo yum update -y
Now install all individual packages inside the repository along with ansible.

$ sudo yum install python python-devel python-pip openssl ansible -y


# vi /etc/ansible/hosts and create ur group [demo] pointing to pvt ips of both destination instances

# Ex 1: Ungrouped hosts, specify before any group headers.

[demo]

172.31.35.72
172.31.45.22

## green.example.com
## blue.example.com
## 192.168.100.1


# vi /etc/ansible/ansible.cfg

uncomment inventory and sudo user sections 


## now create ansible user on all 3 servers

adduser ansible
passwd ansible


#become ansible user on each server now:

su - ansible

yum install httpd -y

#Right now ansible user doesnt have permisions , give permisions :

visudo 

#and make below changes :add ansible user

## Allow root to run any commands anywhere
root    ALL=(ALL)       ALL
ansible ALL=(ALL)       NOPASSWD: ALL

# try entering in ur nodes from main ansible server :
ull get permisions access error...like below:

[ansible@ansible-main ~]$ ssh 172.31.35.72
The authenticity of host '172.31.35.72 (172.31.35.72)' can't be established.
ECDSA key fingerprint is SHA256:Nr0fmk07JULI89py88lTNtpUtg1Vk3ml+Wi0TkTwXfY.
ECDSA key fingerprint is MD5:a9:2e:7a:2e:2a:e2:eb:fa:2e:c9:50:b6:97:42:9a:f1.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.31.35.72' (ECDSA) to the list of known hosts.
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).


from ur main ansible server ,and both nodes
become root again and go to /etc/ssh/sshd_config
uncomment permit root login yes 

aand

uncommment password authentication like below :
# To disable tunneled clear text passwords, change to no here!
PasswordAuthentication yes
#PermitEmptyPasswords no
#PasswordAuthentication no


# on all servers to refresh sshd daemon :
sudo systemctl restart sshd


# we need a keypair to remove password dependency 
# on main server:
ssh-keygen

# public-pvt keypairs are generated ..

send the pub key to both nodes 

[ansible@ansible-main .ssh]$ ssh-copy-id ansible@172.31.35.72
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/ansible/.ssh/id_rsa.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
ansible@172.31.35.72's password:

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh 'ansible@172.31.35.72'"
and check to make sure that only the key(s


do above and send pub key on both nodes from main



------------------------

infrasructire is ready :


ad-hoc commands :

ansible --help
   18  ansible --all -a
   19  clear
   20  ansible all -a "ls"
   21  ansible all -a "touch myfile"
   22  ansible all -a "ls"
   23  ansible --help
   24  clear
   25  ansible demo -a "ls -la"
   26  ansible demo -a "yum install httpd -y"
   27  ansible demo -a "sudo yum install httpd -y"
   28  ansible demo -a "rpm -qa | grep -i httpd "
   29  ansible demo -a "which httpd "
   30  ansible demo -a "sudo which httpd "


modules :


35  ansible-doc
   36  ansible-doc -l
   37  ansible demo -b -m yum -a "pkg=httpd state=present"
   38  ansible demo -b -m yum -a "pkg=httpd state=latest"
   39  ansible demo -b -m yum -a "pkg=httpd state=absent"
   40  ansible demo -b -m yum -a "pkg=httpd state=present"
   41  ansible demo -b -m service -a "name=httpd state=started"
   42  ansible-doc -l | grep -i user
   43  ansible-doc -l | grep  user
   44  ansible demo -b -m user -a "name=raman"
   45  ansible demo -b -m copy --help
   46  ansible demo -b -m copy -h
   47  ansible demo -m setup -a "filter=*ipv4*"

